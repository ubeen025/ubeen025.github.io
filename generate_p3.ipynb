{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains all the code necessary to complete part 3 of the mini-project. You should start by copying over your correct implementation of parts 1 and 2 into the definitions here. Once you have done so, you are responsible for running the analysis functions given to you and using the output to complete your response to the part 3 questions on Prairielearn.\n",
    "\n",
    "**YOU MUST SUBMIT THIS SCRIPT ON PRAIRIELEARN AS A LINK IN YOUR CLASS-PROVIDED GITHUB.** Use this link for details https://courses.grainger.illinois.edu/cs277/sp2024/resources/course-git/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT:\n",
    "# f1, a string containing the file path to the first file being compared\n",
    "# f2, a string containing the file path to the second file being compared\n",
    "# OUTPUT:\n",
    "# A boolean (True) if the files are identical and (False) otherwise.\n",
    "# It also prints the first line pair which is not identical after whitespace is stripped\n",
    "def compareFiles(f1, f2):\n",
    "    with open(f1, 'r') as myf1:\n",
    "        with open(f2, 'r') as myf2:\n",
    "            f1_line = myf1.readline().strip()\n",
    "            f2_line = myf2.readline().strip()\n",
    "            while f1_line or f2_line:\n",
    "                if f1_line != f2_line:\n",
    "                    print(\"F1: {}\".format(f1_line))\n",
    "                    print(\"F2: {}\".format(f2_line))\n",
    "                    return False\n",
    "                f1_line = myf1.readline().strip()\n",
    "                f2_line = myf2.readline().strip()\n",
    "    return True\n",
    "\n",
    "#compareFiles(\"example1.csv\", \"example1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# generateRow\n",
    "# Create a string storing a .csv formatted row line of the appropriate size and min/max given\n",
    "# INPUT:\n",
    "# minval, an optional integer specifying the minimum [inclusive] random value to generate. Default is 0\n",
    "# maxval, an optional integer specifying the maximum [inclusive] random value to generate. Default is 99\n",
    "# calcount, an optional integer argument storing the number of columns in the row. Default is 2\n",
    "# seed, an optional argument storing the seed of Python's random module. Default is None\n",
    "# OUTPUT:\n",
    "# A string storing the row of the CSV\n",
    "def generateRow(minval=0, maxval=99, colcount=2, seed=None):\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    string=''\n",
    "    for i in range(colcount):\n",
    "        rand= random.randint(minval,maxval)\n",
    "        string+= str(rand)\n",
    "        if i < colcount -1:\n",
    "            string+=','\n",
    "    \n",
    "    string +='\\n'\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# generateCSV\n",
    "# Create a .csv file containing random numbers of the specified size and min/max given\n",
    "# To match the autograder, you should generate rows from top to bottom using generateRow()\n",
    "# You should NOT pass the seed argument to generateRow() -- what happens if you do?\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the csv file to be created (always ends in .csv)\n",
    "# minval, an optional integer specifying the minimum [inclusive] random value to generate. Default is 0\n",
    "# maxval, an optional integer specifying the maximum [inclusive] random value to generate. Default is 99\n",
    "# rowcount, an optional integer argument storing the number of rows to generate for the CSV. Default is 100\n",
    "# calcount, an optional integer argument storing the number of columns in the row. Default is 2\n",
    "# seed, an optional argument storing the seed of Python's random module. Default is None\n",
    "# OUTPUT:\n",
    "# None, instead a file is created at the path specified by fname with the content described above\n",
    "def generateCSV(fname, minval=0, maxval=99, rowcount=100, colcount=2, seed=None):\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    with open(fname,'w') as f:\n",
    "        for i in range(rowcount):\n",
    "            f.write(generateRow(minval,maxval,colcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "\n",
    "# generateString\n",
    "# Create a line-separated list of random strings from an input alphabet\n",
    "# To match the autograder, you should generate strings one character at a time sampling with replacement\n",
    "# This will require using random.choice()\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# linelen, a required integer describing the length of each string being generated\n",
    "# linecount, a required integer describing the total number of strings to generate\n",
    "# charList, an optional list of strings storing the alphabet to generate with. Default is ascii_lowercase\n",
    "# seed, an optional argument storing the seed of Python's random module. Default is None\n",
    "# OUTPUT:\n",
    "# None, instead a file is created at the path specified by fname with the content described above\n",
    "def generateString(fname, linelen, linecount, charList=list(string.ascii_lowercase), seed=None):\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    with open(fname,'w') as file:\n",
    "        for i in range(linecount):\n",
    "            string=''\n",
    "            for j in range(linelen):\n",
    "                string+= random.choice(charList)\n",
    "                \n",
    "            file.write(string+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# generateGraph\n",
    "# Create a line-separated list of edges given an input list of strings and an edge count\n",
    "# Each edge is stored on its own line as a start and end vertex using a space-separated string\n",
    "# To match the autograder, you should generate pairs of strings using random.sample()\n",
    "# Unlike random.choice(), sample will sample without replacement.\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# inList, a required list of strings storing the vertices (nodes) of the graph being generated\n",
    "# edges, an optional argument storing the number of edges to generate. Default value is 5 edges\n",
    "# seed, an optional argument storing the seed of Python's random module. Default is None\n",
    "# OUTPUT:\n",
    "# None, instead a file is created at the path specified by fname with the content described above\n",
    "def generateGraph(fname, inList, edges=5, seed=None):\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    with open(fname, 'w') as f:\n",
    "        \n",
    "        for i in range(edges):\n",
    "            string=''\n",
    "            samples= random.sample(inList,2)\n",
    "            string+=' '.join(samples)\n",
    "            f.write(string+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# getRowMax\n",
    "# Finds the maximum integer value for a given row in a csv formatted file\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the csv file to be created (always ends in .csv)\n",
    "# row, a required integer storing the index of the row to search. The index is 0 based (the first row is row 0).\n",
    "# OUTPUT:\n",
    "# An integer output storing the maximum value present in the input row, or -1 if the row does not exist.\n",
    "def getRowMax(fname, row):\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        mylines= f.readlines()\n",
    "        \n",
    "        if row<len(mylines):\n",
    "            split= mylines[row].strip().split(',')\n",
    "            maxi=max(split)\n",
    "            return(int(maxi))\n",
    "            \n",
    "        elif row<0:\n",
    "            return(-1)\n",
    "        else:\n",
    "            return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# countTotalOccurrences\n",
    "# Count the number of exact matches given a csv file and a value of interest.\n",
    "#\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# inVal, a required integer storing the value being searched for throughout the document\n",
    "# OUTPUT:\n",
    "# An integer storing the total number of times inVal is present anywhere in the csv\n",
    "\n",
    "def countTotalOccurrences(fname, inVal):\n",
    "    Total_Occ=0\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        for i in f:\n",
    "            strip= i.strip().split(',')\n",
    "            Total_Occ+= strip.count(str(inVal))\n",
    "                                    \n",
    "    return Total_Occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# countUniqueStrings\n",
    "# Count the number of unique strings present in a file. Each line is its own string\n",
    "#\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# OUTPUT:\n",
    "# An integer storing the count of unique strings in the file\n",
    "def countUniqueStrings(fname):\n",
    "    with open(fname) as f:\n",
    "        mylines= f.readlines()\n",
    "        \n",
    "        unique=[]\n",
    "        for x in mylines:\n",
    "            if x not in unique:\n",
    "                unique.append(x)\n",
    "    \n",
    "    return len(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# firstMatchingSubstring\n",
    "# Find and return the index (0-based) of the line that first contains the input string\n",
    "# If the input string is not present in the file, return -1\n",
    "#\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# inStr, a required string storing the substring to look for in each line\n",
    "# OUTPUT:\n",
    "# The 0-based index of the match (or -1 if the substring is not present)\n",
    "def firstMatchingSubstring(fname, inStr):\n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "        line_number = 0\n",
    "        for i in lines:\n",
    "            if inStr in i:\n",
    "                return line_number\n",
    "            line_number += 1\n",
    "        return -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# getNeighbors\n",
    "# Find and return a list of all neighbors for a given input vertex\n",
    "# You may assume all input text files are edge list formatted.\n",
    "# '<str1> <str2>' implies an edge between vertex str1 and vertex str2\n",
    "# NOTE: Edges are bidirectional! 'A B' is both an edge from A to B and an edge from B to A\n",
    "#\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# inStr, a required string storing the substring to look for in each line\n",
    "# OUTPUT:\n",
    "# A list of strings storing the neighbors of the input vertex. Each neighbor should be listed once.\n",
    "# If there are no neighbors, return an empty list\n",
    "def getNeighbors(fname, inStr):\n",
    "    # Initialize an empty list to store neighbors\n",
    "    neighbors = []\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            # Split the line into two vertices\n",
    "            vertices = line.strip().split()\n",
    "            # Check if the input vertex is present in the line\n",
    "            if inStr in vertices:\n",
    "                # Find the neighbor vertex and add it to the list\n",
    "                neighbor = vertices[1 - vertices.index(inStr)]  # Get the other vertex\n",
    "                if neighbor not in neighbors:\n",
    "                    neighbors.append(neighbor)\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade\n",
    "\n",
    "# checkPathExists\n",
    "# Find and return a list of all neighbors for a given input vertex\n",
    "# You may assume all input text files are edge list formatted.\n",
    "# '<str1> <str2>' implies an edge between vertex str1 and vertex str2\n",
    "# NOTE: Edges are bidirectional! 'A B' is both an edge from A to B and an edge from B to A\n",
    "#\n",
    "# INPUT:\n",
    "# fname, a required string storing the name of the text file to be created (always ends in .txt)\n",
    "# inList, a required list storing a path through the graph as an ordered list of string vertices\n",
    "# You may assume inList is at least length 2, but it may contain vertices which dont exist\n",
    "# OUTPUT:\n",
    "# A bool (True or False) based on whether the path given as input exists in the graph\n",
    "# That is to say, check that each edge transition is directly possible\n",
    "def checkPathExists(fname, inList):\n",
    "    #your code here       \n",
    "    edges = []\n",
    "\n",
    "    # Read the file and populate the edges list\n",
    "    with open(fname, 'r') as file:\n",
    "        for line in file:\n",
    "            vertices = line.strip().split()\n",
    "            edges.append((vertices[0], vertices[1]))\n",
    "            edges.append((vertices[1], vertices[0]))  # Add the reverse edge as well\n",
    "\n",
    "    # Check if each transition in the path is directly possible\n",
    "    for i in range(len(inList) - 1):\n",
    "        edge = (inList[i], inList[i + 1])\n",
    "        if edge not in edges and (edge[1], edge[0]) not in edges:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 code starts here**\n",
    "\n",
    "**Do not run this on Prairielearn.** \n",
    "\n",
    "Running these commands will generate ~80 MB worth of files (part of the reason we are generating our own instead of downloading a set of files hosted online). This should be trivial on your local machine (and can be deleted after you finish the assignment) but is not something Prairielearn is designed for. If you do so, you may fill up your workspace partition and be unable to submit your work or be forced to restart your entire submission. You have been warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeCSV=True\n",
    "makeString=True\n",
    "makeGraph = True\n",
    "\n",
    "# If you are concerned for disk space, consider generating these files one at a time.\n",
    "\n",
    "# Run this line once to make the directory necessary for data\n",
    "# And then comment it out afterward!\n",
    "import os\n",
    "os.mkdir('data')\n",
    "\n",
    "\n",
    "if(makeCSV):\n",
    "    for count in [2**6, 2**7, 2**8, 2**9, 2**10, 2**11, 2**12]:\n",
    "        generateCSV(\"data/csv_r{}_c{}.csv\".format(count, count), rowcount=count, colcount=count)\n",
    "\n",
    "if(makeString):\n",
    "    for pow in [10, 11, 12, 13, 14, 15, 16, 17, 18]:\n",
    "        generateString(\"data/string_r{}_c8.txt\".format(2**pow), 8, 2**pow, [\"T\", \"C\", \"G\", \"A\"])\n",
    "\n",
    "if(makeGraph):\n",
    "    for pow in [15, 16, 17, 18, 19, 20]:\n",
    "        generateGraph(\"data/graph_r{}_c8.txt\".format(2**pow), inList=list(string.ascii_uppercase), edges=2**pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these commands only after generating the above files. The separation here will allow you to rerun the analysis scripts without generating new files every time. You are encouraged to generate files more than once just to observe how the behavior may change for a different 'dataset', but are only required to submit the runtimes once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1: countTotalOccurrences()** We will use the csv generated datasets here to observe how the minimium time and maximum runtime change over seven different datasets (each one doubling in size). We will repeat the analysis 5 times picking a random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min and Max times for countTotalOccurrences() function with shifting rowcount:\n",
      "[0.0006830999627709389, 0.0022680999245494604, 0.008984899963252246, 0.03291850001551211, 0.1211666000308469, 0.5176310000242665, 2.091332199983299]\n",
      "[0.023880799999460578, 0.014668800053186715, 0.031702299951575696, 0.043647599988617, 0.1447246999014169, 0.5646699999924749, 2.224810800049454]\n"
     ]
    }
   ],
   "source": [
    "minList = []\n",
    "maxList = []\n",
    "\n",
    "for rowcount in [2**6, 2**7, 2**8, 2**9, 2**10, 2**11, 2**12]:\n",
    "    mintime=-1\n",
    "    maxtime=-1\n",
    "    for i in range(5):\n",
    "        val = random.randint(0, 99)\n",
    "        start = timeit.default_timer()\n",
    "        countTotalOccurrences(\"data/csv_r{}_c{}.csv\".format(rowcount, rowcount),val)\n",
    "        end = timeit.default_timer()\n",
    "\n",
    "        time = end-start\n",
    "\n",
    "        if mintime == -1:\n",
    "            mintime = time\n",
    "        elif time < mintime:\n",
    "            mintime = time\n",
    "\n",
    "        if maxtime == -1:\n",
    "            maxtime = time\n",
    "        elif time > maxtime:\n",
    "            maxtime = time\n",
    "\n",
    "    minList.append(mintime)\n",
    "    maxList.append(maxtime)\n",
    "\n",
    "print(\"Min and Max times for countTotalOccurrences() function with shifting rowcount:\")\n",
    "print(minList)\n",
    "print(maxList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 2: countUniqueStrings()** We will use the txt generated string datasets here to observe how the minimium time and maximum runtime change over five orders of magnitude differences in our dataset. We will repeat the analysis 500 times picking random rows each time to try to get a more accurate number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique strings with shifting rowcount:\n",
      "[1013, 2016, 3973, 7702, 14462, 25811, 41316, 56616, 64330]\n",
      "Runtime with shifting rowcount:\n",
      "[0.02082530001644045, 0.04053100000601262, 0.10817939997650683, 0.4094054000452161, 1.3655458999564871, 4.569049300043844, 13.933352499967441, 37.83611349994317, 476.66960299992934]\n"
     ]
    }
   ],
   "source": [
    "uniqueStrings = []\n",
    "time_list = []\n",
    "\n",
    "for pow in [10, 11, 12, 13, 14, 15, 16, 17, 18]:\n",
    "    rowcount = 2**pow\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    uniqueStrings.append(countUniqueStrings(\"data/string_r{}_c8.txt\".format(rowcount)))\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    time = end-start\n",
    "\n",
    "    time_list.append(time)\n",
    "\n",
    "print(\"Unique strings with shifting rowcount:\")\n",
    "print(uniqueStrings)\n",
    "print(\"Runtime with shifting rowcount:\")\n",
    "print(time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 3: checkPathExists()** We will use the txt generated graph datasets here to observe how the runtime for exploring a path using an edge list changes as both the edge list and query path length changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For query length: 5\n",
      "Runtime with increasing edge count:\n",
      "[0.05179870000574738, 0.06709889997728169, 0.10773879999760538, 0.2104027000023052, 0.40333619993180037, 0.7423142000334337]\n",
      "For query length: 10\n",
      "Runtime with increasing edge count:\n",
      "[0.018186400062404573, 0.05352039996068925, 0.06727580004371703, 0.17367160005960613, 0.3403373999753967, 0.7184463000157848]\n",
      "For query length: 15\n",
      "Runtime with increasing edge count:\n",
      "[0.015133600099943578, 0.03031509998254478, 0.0776783999754116, 0.19868720008525997, 0.38368059997446835, 0.8104907999513671]\n",
      "For query length: 20\n",
      "Runtime with increasing edge count:\n",
      "[0.016061300062574446, 0.03906969993840903, 0.09696399990934879, 0.23739819996990263, 0.3782607999164611, 0.7551390000153333]\n",
      "For query length: 25\n",
      "Runtime with increasing edge count:\n",
      "[0.022562899976037443, 0.04542790004052222, 0.0975289000198245, 0.1876672999933362, 0.3559406000422314, 0.8053074999479577]\n"
     ]
    }
   ],
   "source": [
    "for qlen in [5, 10, 15, 20, 25]:\n",
    "    print(\"For query length: {}\".format(qlen))\n",
    "    time_list = []\n",
    "    for pow in [15, 16, 17, 18, 19, 20]:\n",
    "        rowcount = 2**pow\n",
    "\n",
    "        # Generate a random query from the allowable vertices\n",
    "        query = random.sample(string.ascii_uppercase, qlen)\n",
    "        random.shuffle(query)\n",
    "\n",
    "        start = timeit.default_timer()\n",
    "        checkPathExists(\"data/graph_r{}_c8.txt\".format(rowcount), query)\n",
    "        end = timeit.default_timer()\n",
    "\n",
    "        time = end-start\n",
    "\n",
    "        time_list.append(time)\n",
    "\n",
    "    print(\"Runtime with increasing edge count:\")\n",
    "    print(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
